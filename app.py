import streamlit as st
import os
import numpy as np
import matplotlib.pyplot as plt
from pose_utils import extract_keypoints_from_video, overlay_skeleton
from compare_utils import compare_dances, frame_similarity
from feedback_utils import generate_feedback

st.set_page_config(page_title="Dance Pose Analyzer", layout="wide")

st.title("ğŸ’ƒ á»¨ng dá»¥ng cháº¥m Ä‘iá»ƒm & so sÃ¡nh Ä‘á»™ng tÃ¡c mÃºa")
st.caption("Chá»n bÃ i mÃºa chuáº©n, táº£i video cá»§a báº¡n vÃ  xem so sÃ¡nh trá»±c quan ğŸ‡»ğŸ‡³")

# 1ï¸âƒ£ Chá»n bÃ i mÃºa chuáº©n
dance_options = {
    "MÃºa xoÃ¨": "samples/xoÃ¨/standard.mp4",
    "MÃºa quáº¡t": "samples/quat/standard.mp4",
    "MÃºa nÃ³n": "samples/non/standard.mp4"
}

dance_choice = st.selectbox("ğŸ­ Chá»n bÃ i mÃºa:", list(dance_options.keys()))
standard_path = dance_options[dance_choice]

col1, col2 = st.columns(2)
with col1:
    st.markdown("### ğŸ“¹ Video máº«u")
    if os.path.exists(standard_path):
        st.video(standard_path)
    else:
        st.warning(f"âš ï¸ Thiáº¿u video máº«u: {standard_path}")

# 2ï¸âƒ£ Upload video ngÆ°á»i há»c
uploaded_file = st.file_uploader("ğŸ“¤ Táº£i video cá»§a báº¡n", type=["mp4", "mov"])

user_path = None
if uploaded_file:
    save_dir = f"samples/user_uploads/{dance_choice.replace(' ', '_')}/"
    os.makedirs(save_dir, exist_ok=True)
    user_path = os.path.join(save_dir, uploaded_file.name)
    with open(user_path, "wb") as f:
        f.write(uploaded_file.read())
    with col2:
        st.markdown("### ğŸ¥ Video cá»§a báº¡n")
        st.video(user_path)

# 3ï¸âƒ£ Khi cÃ³ cáº£ 2 video
if user_path and os.path.exists(standard_path):
    st.markdown("---")
    st.subheader("ğŸ” So sÃ¡nh chi tiáº¿t")

    # Hiá»ƒn thá»‹ song song video skeleton
    st.markdown("### ğŸ¦´ Hiá»ƒn thá»‹ khung xÆ°Æ¡ng (Pose Skeleton)")
    colA, colB = st.columns(2)
    with st.spinner("Äang xá»­ lÃ½ skeleton..."):
        standard_overlay = overlay_skeleton(standard_path, "temp_standard.mp4")
        user_overlay = overlay_skeleton(user_path, "temp_user.mp4")

    with colA:
        st.markdown("**ğŸ“º Video máº«u (pose)**")
        st.video(standard_overlay)
    with colB:
        st.markdown("**ğŸ§ Video cá»§a báº¡n (pose)**")
        st.video(user_overlay)

    # TÃ­nh Ä‘iá»ƒm theo thá»i gian
    st.markdown("### ğŸ“ˆ Biá»ƒu Ä‘á»“ khá»›p Ä‘á»™ng tÃ¡c theo thá»i gian")

    seq_standard = extract_keypoints_from_video(standard_path)
    seq_user = extract_keypoints_from_video(user_path)
    frame_scores = frame_similarity(seq_standard, seq_user)
    avg_score = compare_dances(seq_standard, seq_user)

    fig, ax = plt.subplots()
    ax.plot(frame_scores, label="Äiá»ƒm tá»«ng frame")
    ax.set_ylim(0, 100)
    ax.set_xlabel("Thá»i gian (frame)")
    ax.set_ylabel("Äiá»ƒm khá»›p (%)")
    ax.set_title(f"Äá»™ khá»›p Ä‘á»™ng tÃ¡c - {dance_choice}")
    ax.legend()
    st.pyplot(fig)

    # Thanh trÆ°á»£t Ä‘á»“ng bá»™ video
    st.markdown("### ğŸšï¸ Tua video Ä‘á»“ng bá»™")
    total_frames = min(len(seq_standard), len(seq_user))
    frame_idx = st.slider("Chá»n vá»‹ trÃ­ (frame)", 0, total_frames - 1, 0)

    st.info(f"ğŸ“ Äang xem frame thá»© {frame_idx} â€“ Ä‘iá»ƒm: {frame_scores[frame_idx]:.1f}%")

    st.success(f"ğŸ¯ Äiá»ƒm trung bÃ¬nh toÃ n bÃ i: **{avg_score}/100**")
        # ğŸ§  Gá»¢I Ã Cáº¢I THIá»†N Cá»¤ THá»‚
    st.markdown("### ğŸ§  Gá»£i Ã½ cáº£i thiá»‡n Ä‘á»™ng tÃ¡c")

    feedback_list = generate_feedback(seq_standard, seq_user)
    for fb in feedback_list:
        st.markdown(f"- {fb}")


